---
import ProjectLayout from '../../layouts/ProjectLayout.astro';

const frontmatter = {
  title: "Customer Churn Prediction",
  description: "ML classification model predicting customer churn for a telecommunications company using advanced feature engineering and business-focused evaluation metrics.",
  technologies: ["Python", "Scikit-learn", "Pandas", "FastAPI", "Docker", "PostgreSQL", "Jupyter"],
  outcome: "Reduced churn by 23% through predictive modeling and targeted interventions",
  timeline: "3 months",
  role: "ML Engineer & Data Scientist",
  repoUrl: "https://github.com/solvin-it/customer-churn",
  liveUrl: null,
};
---

<ProjectLayout {...frontmatter}>
  
## Overview

In this project, I developed a machine learning system to predict customer churn for a telecommunications company. The challenge was not just building an accurate model, but creating actionable insights that the business could use to proactively retain valuable customers.

## The Problem

The telecommunications company was experiencing a 15% monthly churn rate, with customer acquisition costs significantly higher than retention costs. They needed a system that could:

- **Identify at-risk customers** 30-60 days before they were likely to churn
- **Provide actionable insights** about why customers were leaving
- **Integrate seamlessly** with existing CRM and marketing automation systems
- **Scale efficiently** to handle 500K+ customers

## My Approach

### 1. Understanding the Business Context

Before diving into modeling, I spent time with stakeholders to understand:
- Customer lifecycle and touchpoints
- Existing retention strategies and their effectiveness
- Available data sources and quality constraints
- Success metrics that aligned with business objectives

### 2. Data Engineering & Feature Development

I worked with multiple data sources to create a comprehensive feature set:

```python
# Key feature categories developed:
features = {
    'demographic': ['age', 'tenure', 'location', 'contract_type'],
    'usage_patterns': ['monthly_usage', 'usage_trends', 'peak_hours'],
    'service_interactions': ['support_tickets', 'complaint_severity', 'resolution_time'],
    'financial': ['payment_method', 'payment_delays', 'plan_changes'],
    'engagement': ['app_usage', 'self_service_adoption', 'loyalty_program']
}
```

**Feature Engineering Highlights:**
- Created time-series features capturing usage pattern changes
- Developed composite metrics like "satisfaction score" from support interactions
- Built lag features to capture seasonal and trending behaviors
- Applied domain knowledge to engineer business-relevant features

### 3. Model Development & Evaluation

I experimented with multiple algorithms and evaluation approaches:

**Models Tested:**
- Random Forest (baseline)
- XGBoost (primary model)
- Logistic Regression (interpretability)
- Neural Networks (deep patterns)

**Business-Focused Evaluation:**
Rather than optimizing for accuracy alone, I focused on metrics that mattered to the business:
- **Precision at top 10%**: Ensuring high-value interventions weren't wasted
- **Recall at 60-day horizon**: Catching churners with enough lead time
- **Feature importance**: Providing actionable insights for retention teams

### 4. Model Interpretability & Insights

The final XGBoost model achieved 87% precision on the top 10% of at-risk customers. Key insights included:

- **Payment behavior** was the strongest predictor (more than usage patterns)
- **Support interaction quality** had significant impact on retention
- **Contract flexibility** was crucial for long-term customer satisfaction

## Technical Implementation

### Model Pipeline
```python
# Simplified pipeline architecture
pipeline = Pipeline([
    ('preprocessing', FeatureTransformer()),
    ('feature_selection', SelectKBest(k=50)),
    ('model', XGBClassifier(
        n_estimators=500,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8
    ))
])
```

### Production Deployment
- **FastAPI** service for real-time predictions
- **Docker containerization** for consistent deployment
- **PostgreSQL** for feature storage and model metadata
- **Automated retraining** pipeline with data drift detection

### Model Monitoring
Implemented comprehensive monitoring including:
- Feature drift detection
- Model performance tracking
- Business impact measurement
- Automated alerts for anomalies

## Results & Impact

### Quantitative Results
- **23% reduction** in monthly churn rate
- **87% precision** on top 10% at-risk customers
- **$2.3M annual savings** from improved retention
- **45% improvement** in marketing campaign effectiveness

### Business Impact
- **Proactive retention**: Customer success team could intervene before churn
- **Targeted campaigns**: Marketing focused resources on highest-value at-risk customers  
- **Process improvements**: Insights led to changes in onboarding and support processes
- **Cost optimization**: Reduced waste in retention spending by 40%

## Technical Challenges & Solutions

### Challenge: Data Quality & Consistency
**Problem**: Multiple data sources with different update frequencies and quality standards.
**Solution**: Built robust data validation pipeline with automated quality checks and imputation strategies.

### Challenge: Model Interpretability vs Performance
**Problem**: Business stakeholders needed to understand "why" predictions were made.
**Solution**: Combined XGBoost performance with SHAP explanations and created simplified decision rules for front-line teams.

### Challenge: Concept Drift
**Problem**: Customer behavior patterns evolved over time, affecting model performance.
**Solution**: Implemented automated retraining with drift detection and A/B testing framework for model updates.

## Lessons Learned

1. **Business alignment is crucial**: The most technically impressive model is worthless without business buy-in and actionable outcomes.

2. **Feature engineering > algorithm choice**: Domain expertise and thoughtful feature creation had more impact than choosing the "best" algorithm.

3. **Production considerations from day 1**: Designing for deployment, monitoring, and maintenance from the beginning saved months of refactoring.

4. **Interpretability enables adoption**: Even with a "black box" model, providing explanations was essential for stakeholder confidence and adoption.

## Next Steps

This project established the foundation for a comprehensive customer intelligence platform. Future enhancements include:
- **Customer lifetime value prediction** for more nuanced retention strategies
- **Real-time intervention recommendations** based on customer state
- **Automated A/B testing** for retention campaign optimization
- **Multi-model ensemble** for improved robustness

The success of this project led to expansion of ML initiatives across other business units and established ML as a core capability for the organization.

</ProjectLayout>